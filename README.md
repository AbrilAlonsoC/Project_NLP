# Friends TV Show Chatbot (RAG System)

A lightweight multilingual Retrieval-Augmented Generation (RAG) chatbot based on the TV show Friends.  
It answers user questions by retrieving relevant script chunks and generating grounded, contextualized responses.

---

## ğŸ“š Project Overview

- **Multilingual support**: Input in English, Spanish, French, German, Portuguese, Italian, or Chinese.
- **Translation Layer**: Automatic translation (via MarianMT) to English for processing, then back to the input language.
- **Document database**: 234 scripts from all episodes of Friends, processed into individual Markdown files.
- **Retrieval-augmented**: Semantic search over embeddings to find relevant content before generation.
- **LLM**: meta-llama/llama-4-scout:free via OpenRouter API.
- **Frontend**: Streamlit-based chat interface with styled chat bubbles and persistent history.

---

## ğŸ› ï¸ Technologies Used

- `transformers` (MarianMT models for translation)
- `sentence-transformers` (distiluse-base-multilingual-cased-v2 for embeddings)
- `bert-score` and `SBERT` (evaluation metrics)
- `streamlit` (frontend interface)
- `litellm` (LLM API interaction via OpenRouter)
- `langdetect` (language detection)

---

## ğŸ—‚ï¸ Repository Structure
```
root/
â”œâ”€â”€ conversor.py                 # Convert TXT scripts to Markdown.
â”œâ”€â”€ crear_indice.py              # Build the vector index (chunks + embeddings).
â”œâ”€â”€ inferencia_interfaz.py       # Backend to handle question answering logic.
â”œâ”€â”€ interfaz.py                  # Streamlit web app interface for the chatbot.
â”œâ”€â”€ helpers/                     # Folder containing all helper modules.
â”‚   â”œâ”€â”€ crear_indice.py          # Functions for chunking documents and creating embeddings.
â”‚   â”œâ”€â”€ hacer_inferencia.py      # Retrieval and LLM inference functions.
â”‚   â”œâ”€â”€ metrics.py               # Evaluation metrics (BERTScore, SBERT Cosine, Exact Match Rate).
â”‚   â”œâ”€â”€ LLM_prompts.py           # Custom system prompt for controlled LLM behavior.
â”‚   â””â”€â”€ translation.py           # Language detection and translation using MarianMT models.
â”œâ”€â”€ data/                        # Folder with the script datasets.
â”‚   â”œâ”€â”€ scripts_friends/         # Original Friends TV show scripts in TXT format.
â”‚   â””â”€â”€ scripts_friends_md/      # Converted scripts in Markdown format.
â”œâ”€â”€ Indice/                      # Folder where chunks and embeddings are saved.
â”œâ”€â”€ Interfaz-Images/             # Background images for the Streamlit app.
â”œâ”€â”€ .env                         # Environment file storing OpenRouter API key (not pushed to GitHub).
â””â”€â”€ requirements.txt             # Python dependencies required for the project.
```

---
## ğŸ”‘ OpenRouter API Key Setup

An example `.env` file is already included in the repository.  
It looks like this:

```ini
# Replace this API key with your own OpenRouter key to avoid hitting shared usage limits (200 requests per user).
You can register and obtain a free API key here: https://openrouter.ai/.
This ensures that you have your own usage quota and are not limited by a shared key.
LLMsAPIkey_v7 = "your_openrouter_api_key_here"

```
---

## âš™ï¸ How to Run

1. Install requirements:

```
pip install -r requirements.txt
```
2. Create a `.env` file in the root directory:

LLMsAPIkey_v7=your_openrouter_api_key_here


3. Build the index:
```
python index.py
````
4. Launch the chatbot interface:
```
streamlit run interfaz.py
````
## ğŸ” Evaluation metrics 

* BERTScore: Measures alignment between generated responses and retrieved content.
* SBERT Cosine Similarity: Measures semantic relevance between the question and the generated response.
* Exact Match Rate: Evaluates presence of expected keywords in answers.
